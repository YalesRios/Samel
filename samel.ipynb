{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "#from tensorflow import keras\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from vis.visualization import visualize_saliency\n",
    "from vis.visualization import get_num_filters\n",
    "from vis.visualization import visualize_activation\n",
    "from vis.utils import utils\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras import activations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Loading Data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = tf.keras.datasets.mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(trainX, trainY),(testX, testY) = data.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = trainX.reshape((trainX.shape[0], 28, 28, 1))\n",
    "testX = testX.reshape((testX.shape[0], 28, 28, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainY = keras.utils.to_categorical(trainY, 10)\n",
    "testY = keras.utils.to_categorical(testY, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = trainX.astype(\"float32\") / 255.0\n",
    "testX = testX.astype(\"float32\") / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(trainX.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creates Sequential model using Keras\n",
    "#Number of nodes is the same as number of features (different number of nodes were tried but it did not\n",
    "#affect validation accuracy significantly)\n",
    "lenet = keras.Sequential([\n",
    "                            #Input layer:\n",
    "                            keras.layers.Conv2D(20, 5, padding=\"same\", input_shape=[28,28,1], use_bias=True),\n",
    "                            #Hidden Layers:\n",
    "                            keras.layers.Activation(activation=\"relu\"),\n",
    "                            keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n",
    "                            keras.layers.Conv2D(50, 5, padding=\"same\"),\n",
    "                            keras.layers.Activation(activation=\"relu\"),\n",
    "                            keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n",
    "                            keras.layers.Flatten(),\n",
    "                            keras.layers.Dense(500),\n",
    "                            keras.layers.Activation(activation=\"relu\"),\n",
    "                            keras.layers.Dense(10, name='vis',use_bias=True),\n",
    "                            #Output layer\n",
    "                            keras.layers.Activation(activation=\"softmax\"),\n",
    "                        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lenets = [keras.models.clone_model(lenet),keras.models.clone_model(lenet),keras.models.clone_model(lenet),keras.models.clone_model(lenet),keras.models.clone_model(lenet),keras.models.clone_model(lenet)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_number = 5\n",
    "lenets = [keras.models.clone_model(lenet)]\n",
    "for i in range(1,classifier_number):\n",
    "    lenets.append(keras.models.clone_model(lenet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Compiles sequential model\n",
    "#Using learning rate 0.01\n",
    "#Loss function will be categorical crossentropy\n",
    "lenet.compile(\n",
    "                optimizer=keras.optimizers.SGD(lr=0.01),\n",
    "                loss = 'categorical_crossentropy',\n",
    "                metrics = ['accuracy']\n",
    "                )\n",
    "#Trains network over a number of epochs and evaluates network agains validation data\n",
    "#after each epoch\n",
    "lenetEpochHistory = lenet.fit(trainX, trainY, epochs = 5, validation_data = (testX, testY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Compiles sequential model\n",
    "#Using learning rate 0.01\n",
    "#Loss function will be categorical crossentropy\n",
    "for model in lenets:\n",
    "    model.compile(\n",
    "                    optimizer=keras.optimizers.SGD(lr=0.01),\n",
    "                    loss = 'categorical_crossentropy',\n",
    "                    metrics = ['accuracy']\n",
    "                    )\n",
    "#Trains network over a number of epochs and evaluates network agains validation data\n",
    "#after each epoch\n",
    "for model in lenets:\n",
    "    model.fit(trainX, trainY, epochs = 5, validation_data = (testX, testY))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicting Label:\n",
    "\n",
    "print(np.argmax(lenet.predict(testX)[100]))\n",
    "print(np.argmax(testY[100]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get accuracy for lenet\n",
    "sequentialLoss, sequentialAccuracy = lenet.evaluate(testX, testY)\n",
    "print('Lenet accuracy: ', sequentialAccuracy)\n",
    "print('Lenet loss: ', sequentialLoss)\n",
    "\n",
    "plt.style.use('dark_background')\n",
    "plt.plot(lenetEpochHistory.history['acc'])\n",
    "plt.plot(lenetEpochHistory.history['val_acc'])\n",
    "plt.title('Neural Network accuracy per epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Training data', 'Validation data'])\n",
    "plt.show()\n",
    "\n",
    "plt.style.use('dark_background')\n",
    "plt.plot(lenetEpochHistory.history['loss'])\n",
    "plt.plot(lenetEpochHistory.history['val_loss'])\n",
    "plt.title('Neural Network loss per epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Training data', 'Validation data'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saliency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#This line outputs the layer_idx that the saliency is meant to be extracted from. (Usually the output layer pre-activation)\n",
    "utils.find_layer_idx(lenet, 'vis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check if that layer is correct by checking if the number of nodes matches the number of outputs\n",
    "get_num_filters(lenet.layers[9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check if the saliency map is working for the singular network\n",
    "input_idx = 1\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2)\n",
    "saliency_map = visualize_saliency(model = lenet,layer_idx = 9, filter_indices = np.argmax(testY[input_idx]), seed_input = testX[input_idx])\n",
    "ax[0].imshow(saliency_map.reshape(28,28),interpolation='nearest')\n",
    "ax[1].imshow(testX[input_idx].reshape(28,28))\n",
    "print(np.sum(saliency_map))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This prints out the pre-activation outputs for the output layer\n",
    "intermediate_layer_model = keras.Model(inputs=lenet.input,\n",
    "                                 outputs=lenet.get_layer(\"vis\").output)\n",
    "intermediate_output = intermediate_layer_model.predict(testX)[input_idx]\n",
    "print(max(intermediate_output))\n",
    "print(lenet.predict(testX)[input_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate multiple saliency maps\n",
    "input_idx = 1\n",
    "saliency_maps = []\n",
    "predicted_classes = []\n",
    "for classifier in lenets:\n",
    "    saliency_maps.append(visualize_saliency(model = classifier,layer_idx = 9, filter_indices = np.argmax(testY[input_idx]), seed_input = testX[input_idx]))\n",
    "    predicted_classes.append(np.argmax(classifier.predict(testX)[input_idx]))\n",
    "\n",
    "image_saliency_maps = saliency_maps\n",
    "fig, ax = plt.subplots(nrows=1, ncols=classifier_number+1, figsize = (15,15))\n",
    "i = 1\n",
    "for s_map in image_saliency_maps:\n",
    "    ax[i].imshow(s_map.reshape(28,28),interpolation=\"nearest\")\n",
    "    i = i+1\n",
    "ax[0].imshow(testX[input_idx].reshape(28,28))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute difference of saliency maps\n",
    "saliency_map_difference = np.std(saliency_maps,axis=0)/np.average(saliency_maps,axis=0)\n",
    "plt.imshow(saliency_map_difference)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Compute the average difference value for each pixel\n",
    "np.average(saliency_map_difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Output the classes predicted by each classifier\n",
    "predicted_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Output classes that were misclassified by the singular classifier\n",
    "idx = 0\n",
    "for i in lenet.predict(testX):\n",
    "    if (np.argmax(i) != np.argmax(testY[idx])):\n",
    "        print(idx)\n",
    "    idx = idx + 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
