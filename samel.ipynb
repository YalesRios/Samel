{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "#from tensorflow import keras\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from vis.visualization import visualize_saliency\n",
    "from vis.visualization import get_num_filters\n",
    "from vis.visualization import visualize_saliency_init\n",
    "from vis.visualization import visualize_saliency_run\n",
    "from vis.utils import utils\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import describe\n",
    "from scipy import ndimage\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Loading Data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = tf.keras.datasets.mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(trainX, trainY),(testX, testY) = data.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = trainX.reshape((trainX.shape[0], 28, 28, 1))\n",
    "testX = testX.reshape((testX.shape[0], 28, 28, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainY = keras.utils.to_categorical(trainY, 10)\n",
    "testY = keras.utils.to_categorical(testY, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = trainX.astype(\"float32\") / 255.0\n",
    "testX = testX.astype(\"float32\") / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(trainX.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creates Sequential model using Keras\n",
    "#Number of nodes is the same as number of features (different number of nodes were tried but it did not\n",
    "#affect validation accuracy significantly)\n",
    "lenet = keras.Sequential([\n",
    "                            #Input layer:\n",
    "                            keras.layers.Conv2D(20, 5, padding=\"same\", input_shape=[28,28,1], use_bias=True),\n",
    "                            #Hidden Layers:\n",
    "                            keras.layers.Activation(activation=\"relu\"),\n",
    "                            keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n",
    "                            keras.layers.Conv2D(50, 5, padding=\"same\"),\n",
    "                            keras.layers.Activation(activation=\"relu\"),\n",
    "                            keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n",
    "                            keras.layers.Flatten(),\n",
    "                            keras.layers.Dense(500),\n",
    "                            keras.layers.Activation(activation=\"relu\"),\n",
    "                            keras.layers.Dense(10, name='vis',use_bias=True),\n",
    "                            #Output layer\n",
    "                            keras.layers.Activation(activation=\"softmax\"),\n",
    "                        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lenets = [keras.models.clone_model(lenet),keras.models.clone_model(lenet),keras.models.clone_model(lenet),keras.models.clone_model(lenet),keras.models.clone_model(lenet),keras.models.clone_model(lenet)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_number = 5\n",
    "lenets = [keras.models.clone_model(lenet)]\n",
    "for i in range(1,classifier_number):\n",
    "    lenets.append(keras.models.clone_model(lenet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Compiles sequential model\n",
    "#Using learning rate 0.01\n",
    "#Loss function will be categorical crossentropy\n",
    "lenet.compile(\n",
    "                optimizer=keras.optimizers.SGD(lr=0.01),\n",
    "                loss = 'categorical_crossentropy',\n",
    "                metrics = ['accuracy']\n",
    "                )\n",
    "#Trains network over a number of epochs and evaluates network agains validation data\n",
    "#after each epoch\n",
    "lenetEpochHistory = lenet.fit(trainX, trainY, epochs = 5, validation_data = (testX, testY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Compiles sequential model\n",
    "#Using learning rate 0.01\n",
    "#Loss function will be categorical crossentropy\n",
    "for model in lenets:\n",
    "    model.compile(\n",
    "                    optimizer=keras.optimizers.SGD(lr=0.01),\n",
    "                    loss = 'categorical_crossentropy',\n",
    "                    metrics = ['accuracy']\n",
    "                    )\n",
    "#Trains network over a number of epochs and evaluates network agains validation data\n",
    "#after each epoch\n",
    "for model in lenets:\n",
    "    model.fit(trainX, trainY, epochs = 5, validation_data = (testX, testY))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicting Label:\n",
    "\n",
    "print(np.argmax(lenet.predict(testX)[100]))\n",
    "print(np.argmax(testY[100]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get accuracy for lenet\n",
    "sequentialLoss, sequentialAccuracy = lenet.evaluate(testX, testY)\n",
    "print('Lenet accuracy: ', sequentialAccuracy)\n",
    "print('Lenet loss: ', sequentialLoss)\n",
    "\n",
    "plt.style.use('dark_background')\n",
    "plt.plot(lenetEpochHistory.history['acc'])\n",
    "plt.plot(lenetEpochHistory.history['val_acc'])\n",
    "plt.title('Neural Network accuracy per epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Training data', 'Validation data'])\n",
    "plt.show()\n",
    "\n",
    "plt.style.use('dark_background')\n",
    "plt.plot(lenetEpochHistory.history['loss'])\n",
    "plt.plot(lenetEpochHistory.history['val_loss'])\n",
    "plt.title('Neural Network loss per epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Training data', 'Validation data'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saliency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This line outputs the layer_idx that the saliency is meant to be extracted from. (Usually the output layer pre-activation)\n",
    "utils.find_layer_idx(lenet, 'vis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check if that layer is correct by checking if the number of nodes matches the number of outputs\n",
    "get_num_filters(lenet.layers[9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check if the saliency map is working for the singular network\n",
    "input_idx = 1\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2)\n",
    "saliency_map = visualize_saliency(model = lenet,layer_idx = 9, filter_indices = np.argmax(testY[input_idx]), seed_input = testX[input_idx])\n",
    "ax[0].imshow(saliency_map.reshape(28,28),interpolation='nearest')\n",
    "ax[1].imshow(testX[input_idx].reshape(28,28))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get optimisers for each network's output node to speed up saliency processing\n",
    "optimisers = []\n",
    "classifiers = lenets\n",
    "for i in range(0,len(classifiers)):\n",
    "    classifier_optmisers = []\n",
    "    for j in range(0,10):\n",
    "        opt = visualize_saliency_init(classifiers[i],9,filter_indices=j)\n",
    "        classifier_optmisers.append(opt)\n",
    "    optimisers.append(classifier_optmisers)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to calculate ensemble outputs (for series of inputs) using mean of outputs\n",
    "def get_ensenmble_outputs(classifiers,classifier_inputs):\n",
    "    predictions = np.zeros((np.size(testX, axis=0), np.size(testY, axis=1)))\n",
    "    for classifier in classifiers:\n",
    "        predictions = predictions + classifier.predict(classifier_inputs)\n",
    "    prediction_average = predictions / classifier_number\n",
    "    outputs = np.apply_along_axis(np.argmax, axis=1, arr=prediction_average)\n",
    "    return(outputs)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to calculate ensemble output (for one input) using mean of outputs\n",
    "def get_ensemble_output(classifiers,classifier_input):\n",
    "    predictions = np.zeros(np.size(testY, axis=1))\n",
    "    for classifier in classifiers:\n",
    "        predictions = predictions + classifier.predict(np.expand_dims(classifier_input,axis=0))\n",
    "    prediction_average = predictions / classifier_number\n",
    "    output = np.argmax(prediction_average)\n",
    "    return(output)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_ensemble_output(lenets,testX[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate multiple saliency maps for each input\n",
    "\n",
    "# If doing this over multiple inputs at a time, it is faster to go over multiple inputs\n",
    "# with the same classifier and then doing the same for the different classifiers. This is \n",
    "# because switching optimisers is computationally expensive.\n",
    "\n",
    "def generate_saliency_maps_for_one_input(classifiers,classifier_input,optimisers,visualised_layer):\n",
    "    output_node = get_ensemble_output(classifiers,classifier_input)\n",
    "    saliency_maps = np.zeros((len(classifiers),classifier_input.shape[0],classifier_input.shape[1]))\n",
    "    for i in range(0,len(classifiers)):\n",
    "        saliency_maps[i] = visualize_saliency_run(model = classifiers[i],layer_idx = visualised_layer, opt = optimisers[i][output_node], seed_input = classifier_input)\n",
    "    return(saliency_maps)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to visualise the multiple saliency maps\n",
    "def visualize_saliency_maps(classifier_input,saliency_maps):\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=len(saliency_maps)+1, figsize = (15,15))\n",
    "    i = 1\n",
    "    for s_map in saliency_maps:\n",
    "        ax[i].imshow(s_map)\n",
    "        i = i+1\n",
    "    ax[0].imshow(classifier_input)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute difference of saliency maps\n",
    "def generate_uncertainty_map(saliency_maps):\n",
    "    return(np.std(saliency_maps,axis=0)/np.average(saliency_maps,axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrapper function to arrive at uncertainty output using classifiers and input\n",
    "def calculate_uncertainty(classifiers,classifier_input,optimisers,visualised_layer):\n",
    "    \n",
    "    saliency_maps = generate_saliency_maps_for_one_input(classifiers = classifiers,\n",
    "                                  classifier_input = classifier_input,\n",
    "                                  optimisers = optimisers,\n",
    "                                  visualised_layer = visualised_layer)\n",
    "    \n",
    "    uncertainty_map = generate_uncertainty_map(saliency_maps)\n",
    "    \n",
    "    return(np.average(uncertainty_map))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute difference of saliency maps\n",
    "def calculate_uncertainty_with_maps(saliency_maps):\n",
    "    return(np.mean(np.std(saliency_maps,axis=0)/np.average(saliency_maps,axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_saliency_maps_for_multiple_inputs(classifier,classifier_inputs,classifier_outputs,\n",
    "                                               classifier_optimisers,visualised_layer):\n",
    "    \n",
    "    saliency_maps = []\n",
    "    for input_idx in tqdm(range(0,np.size(classifier_inputs,axis=0))):\n",
    "        classifier_input = classifier_inputs[input_idx]\n",
    "        output_node = classifier_outputs[input_idx]\n",
    "        saliency_maps.append(visualize_saliency_run(model = classifier,\n",
    "                                                    layer_idx = 9, \n",
    "                                                    opt = classifier_optimisers[output_node],   \n",
    "                                                    seed_input = classifier_input))\n",
    "    return(saliency_maps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ensemble_saliency_maps_for_multiple_inputs(classifiers,\n",
    "                                                        classifier_inputs,classifier_outputs,\n",
    "                                                        optimisers,visualised_layer):\n",
    "    saliency_maps = []\n",
    "    for classifier_idx in range(0,len(classifiers)):\n",
    "        saliency_maps.append(generate_saliency_maps_for_multiple_inputs(\n",
    "                                classifiers[classifier_idx],\n",
    "                                classifier_inputs,\n",
    "                                classifier_outputs,\n",
    "                                optimisers[classifier_idx],\n",
    "                                9))\n",
    "    return(saliency_maps)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "MNIST_ensemble_predicted_outputs = get_ensenmble_outputs(lenets, testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Generate saliency maps examples\n",
    "input_idx = 6\n",
    "maps = generate_saliency_maps_for_one_input(classifiers = lenets,\n",
    "                                            classifier_input = testX[input_idx],\n",
    "                                            optimisers = optimisers,\n",
    "                                            visualised_layer = 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise saliency maps examples\n",
    "visualize_saliency_maps(classifier_input = testX[input_idx].reshape(28,28),\n",
    "                        saliency_maps = maps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mapx in maps:\n",
    "    print(describe(mapx,axis=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise uncertainty map example\n",
    "uncertainty_map = generate_uncertainty_map(maps)\n",
    "plt.imshow(uncertainty_map)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Compute the average difference value for each pixel (uncertainty)\n",
    "np.average(uncertainty_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Â Generating example using wrapper function\n",
    "input_idx = 4\n",
    "uncertainty = calculate_uncertainty(classifiers = lenets,\n",
    "                              classifier_input = testX[input_idx],\n",
    "                              optimisers = optimisers,\n",
    "                              visualised_layer = 9)\n",
    "print(uncertainty)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "generate_saliency_maps_for_multiple_inputs(lenets[0],testX,ensemble_predicted_outputs,optimisers[0],9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MNIST_saliency_maps = generate_ensemble_saliency_maps_for_multiple_inputs(lenets,testX,MNIST_ensemble_predicted_outputs,optimisers,9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MNIST_saliency_maps = np.swapaxes(MNIST_saliency_maps,0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "visualize_saliency_maps(testX[1].reshape(28,28),MNIST_saliency_maps[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MNIST_uncertanties = np.zeros(np.size(MNIST_saliency_maps,axis=0))\n",
    "for i in range(0,np.size(MNIST_saliency_maps, axis=0)):\n",
    "    MNIST_uncertanties[i] = calculate_uncertainty_with_maps(MNIST_saliency_maps[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MNIST_uncertanties[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(MNIST_uncertanties)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Not-MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = './data/notMNIST_small/A'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 28  # Pixel width and height.\n",
    "pixel_depth = 255.0  # Number of levels per pixel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_letter(folder, min_num_images):\n",
    "  \"\"\"Load the data for a single letter label.\"\"\"\n",
    "  image_files = os.listdir(folder)\n",
    "  dataset = np.ndarray(shape=(len(image_files), image_size, image_size),\n",
    "                         dtype=np.float32)\n",
    "  print(folder)\n",
    "  num_images = 0\n",
    "  for image in image_files:\n",
    "    image_file = os.path.join(folder, image)\n",
    "    try:\n",
    "      image_data = (ndimage.imread(image_file).astype(float) - \n",
    "                    pixel_depth / 2) / pixel_depth\n",
    "      if image_data.shape != (image_size, image_size):\n",
    "        raise Exception('Unexpected image shape: %s' % str(image_data.shape))\n",
    "      dataset[num_images, :, :] = image_data\n",
    "      num_images = num_images + 1\n",
    "    except IOError as e:\n",
    "      print('Could not read:', image_file, ':', e, '- it\\'s ok, skipping.')\n",
    "    \n",
    "  dataset = dataset[0:num_images, :, :]\n",
    "  if num_images < min_num_images:\n",
    "    raise Exception('Many fewer images than expected: %d < %d' %\n",
    "                    (num_images, min_num_images))\n",
    "    \n",
    "  print('Full dataset tensor:', dataset.shape)\n",
    "  print('Mean:', np.mean(dataset))\n",
    "  print('Standard deviation:', np.std(dataset))\n",
    "  return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "letter = load_letter(folder,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = tf.keras.datasets.mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(trainX, trainY),(testX, testY) = data.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = trainX.reshape((trainX.shape[0], 28, 28, 1))\n",
    "testX = testX.reshape((testX.shape[0], 28, 28, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainY = keras.utils.to_categorical(trainY, 10)\n",
    "testY = keras.utils.to_categorical(testY, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = trainX.astype(\"float32\") / 255.0\n",
    "testX = testX.astype(\"float32\") / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(trainX.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Misc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This prints out the pre-activation outputs for the output layer (for curiosity)\n",
    "intermediate_layer_model = keras.Model(inputs=lenet.input,\n",
    "                                 outputs=lenet.get_layer(\"vis\").output)\n",
    "intermediate_output = intermediate_layer_model.predict(testX)[input_idx]\n",
    "print(max(intermediate_output))\n",
    "print(lenet.predict(testX)[input_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is what happens if we don't normalise the pixels' standard deviation\n",
    "plt.imshow(np.std(maps,axis=0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Output images that were misclassified by the singular classifier\n",
    "idx = 0\n",
    "for i in lenet.predict(testX):\n",
    "    if (np.argmax(i) != np.argmax(testY[idx])):\n",
    "        print(idx)\n",
    "    idx = idx + 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
