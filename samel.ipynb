{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "#from tensorflow import keras\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from vis.visualization import visualize_saliency\n",
    "from vis.visualization import get_num_filters\n",
    "from vis.visualization import visualize_activation\n",
    "from vis.utils import utils\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras import activations\n",
    "from tqdm import tqdm\n",
    "from numba import jit\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Loading Data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = tf.keras.datasets.mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(trainX, trainY),(testX, testY) = data.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = trainX.reshape((trainX.shape[0], 28, 28, 1))\n",
    "testX = testX.reshape((testX.shape[0], 28, 28, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainY = keras.utils.to_categorical(trainY, 10)\n",
    "testY = keras.utils.to_categorical(testY, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = trainX.astype(\"float32\") / 255.0\n",
    "testX = testX.astype(\"float32\") / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(trainX.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creates Sequential model using Keras\n",
    "#Number of nodes is the same as number of features (different number of nodes were tried but it did not\n",
    "#affect validation accuracy significantly)\n",
    "lenet = keras.Sequential([\n",
    "                            #Input layer:\n",
    "                            keras.layers.Conv2D(20, 5, padding=\"same\", input_shape=[28,28,1], use_bias=True),\n",
    "                            #Hidden Layers:\n",
    "                            keras.layers.Activation(activation=\"relu\"),\n",
    "                            keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n",
    "                            keras.layers.Conv2D(50, 5, padding=\"same\"),\n",
    "                            keras.layers.Activation(activation=\"relu\"),\n",
    "                            keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n",
    "                            keras.layers.Flatten(),\n",
    "                            keras.layers.Dense(500),\n",
    "                            keras.layers.Activation(activation=\"relu\"),\n",
    "                            keras.layers.Dense(10, name='vis',use_bias=True),\n",
    "                            #Output layer\n",
    "                            keras.layers.Activation(activation=\"softmax\"),\n",
    "                        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lenets = [keras.models.clone_model(lenet),keras.models.clone_model(lenet),keras.models.clone_model(lenet),keras.models.clone_model(lenet),keras.models.clone_model(lenet),keras.models.clone_model(lenet)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_number = 5\n",
    "lenets = [keras.models.clone_model(lenet)]\n",
    "for i in range(1,classifier_number):\n",
    "    lenets.append(keras.models.clone_model(lenet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Compiles sequential model\n",
    "#Using learning rate 0.01\n",
    "#Loss function will be categorical crossentropy\n",
    "lenet.compile(\n",
    "                optimizer=keras.optimizers.SGD(lr=0.01),\n",
    "                loss = 'categorical_crossentropy',\n",
    "                metrics = ['accuracy']\n",
    "                )\n",
    "#Trains network over a number of epochs and evaluates network agains validation data\n",
    "#after each epoch\n",
    "lenetEpochHistory = lenet.fit(trainX, trainY, epochs = 5, validation_data = (testX, testY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Compiles sequential model\n",
    "#Using learning rate 0.01\n",
    "#Loss function will be categorical crossentropy\n",
    "for model in lenets:\n",
    "    model.compile(\n",
    "                    optimizer=keras.optimizers.SGD(lr=0.01),\n",
    "                    loss = 'categorical_crossentropy',\n",
    "                    metrics = ['accuracy']\n",
    "                    )\n",
    "#Trains network over a number of epochs and evaluates network agains validation data\n",
    "#after each epoch\n",
    "for model in lenets:\n",
    "    model.fit(trainX, trainY, epochs = 5, validation_data = (testX, testY))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicting Label:\n",
    "\n",
    "print(np.argmax(lenet.predict(testX)[100]))\n",
    "print(np.argmax(testY[100]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get accuracy for lenet\n",
    "sequentialLoss, sequentialAccuracy = lenet.evaluate(testX, testY)\n",
    "print('Lenet accuracy: ', sequentialAccuracy)\n",
    "print('Lenet loss: ', sequentialLoss)\n",
    "\n",
    "plt.style.use('dark_background')\n",
    "plt.plot(lenetEpochHistory.history['acc'])\n",
    "plt.plot(lenetEpochHistory.history['val_acc'])\n",
    "plt.title('Neural Network accuracy per epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Training data', 'Validation data'])\n",
    "plt.show()\n",
    "\n",
    "plt.style.use('dark_background')\n",
    "plt.plot(lenetEpochHistory.history['loss'])\n",
    "plt.plot(lenetEpochHistory.history['val_loss'])\n",
    "plt.title('Neural Network loss per epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Training data', 'Validation data'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saliency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This line outputs the layer_idx that the saliency is meant to be extracted from. (Usually the output layer pre-activation)\n",
    "utils.find_layer_idx(lenet, 'vis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check if that layer is correct by checking if the number of nodes matches the number of outputs\n",
    "get_num_filters(lenet.layers[9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check if the saliency map is working for the singular network\n",
    "input_idx = 1\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2)\n",
    "saliency_map = visualize_saliency(model = lenet,layer_idx = 9, filter_indices = np.argmax(testY[input_idx]), seed_input = testX[input_idx])\n",
    "ax[0].imshow(saliency_map.reshape(28,28),interpolation='nearest')\n",
    "ax[1].imshow(testX[input_idx].reshape(28,28))\n",
    "print(np.sum(saliency_map))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This prints out the pre-activation outputs for the output layer (for curiosity)\n",
    "intermediate_layer_model = keras.Model(inputs=lenet.input,\n",
    "                                 outputs=lenet.get_layer(\"vis\").output)\n",
    "intermediate_output = intermediate_layer_model.predict(testX)[input_idx]\n",
    "print(max(intermediate_output))\n",
    "print(lenet.predict(testX)[input_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to calculate ensemble outputs (vectorised) using mean of outputs\n",
    "def get_ensenmble_outputs(classifiers,classifier_inputs):\n",
    "    predictions = np.zeros((np.size(testX, axis=0), np.size(testY, axis=1)))\n",
    "    for classifier in classifiers:\n",
    "        predictions = predictions + classifier.predict(classifier_inputs)\n",
    "    prediction_average = predictions / classifier_number\n",
    "    outputs = np.apply_along_axis(np.argmax, axis=1, arr=prediction_average)\n",
    "    return(outputs)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "get_ensenmble_outputs(lenets, testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to calculate ensemble output using mean of outputs\n",
    "def get_ensemble_output(classifiers,classifier_input):\n",
    "    predictions = np.zeros(np.size(testY, axis=1))\n",
    "    for classifier in classifiers:\n",
    "        predictions = predictions + classifier.predict(np.expand_dims(classifier_input,axis=0))\n",
    "    prediction_average = predictions / classifier_number\n",
    "    output = np.argmax(prediction_average)\n",
    "    return(output)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_ensemble_output(lenets,testX[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to generate multiple saliency maps\n",
    "def generate_saliency_maps(classifiers,classifier_input,output_node,visualised_layer):\n",
    "    saliency_maps = np.zeros((len(classifiers),classifier_input.shape[0],classifier_input.shape[1]))\n",
    "    for i in range(0,len(classifiers)):\n",
    "        saliency_maps[i] = visualize_saliency(model = classifiers[i],layer_idx = visualised_layer, filter_indices = output_node, seed_input = classifier_input)\n",
    "    return(saliency_maps)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to visualise the multiple saliency maps\n",
    "def visualize_saliency_maps(classifier_input,saliency_maps):\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=len(saliency_maps)+1, figsize = (15,15))\n",
    "    i = 1\n",
    "    for s_map in saliency_maps:\n",
    "        ax[i].imshow(s_map)\n",
    "        i = i+1\n",
    "    ax[0].imshow(classifier_input)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute difference of saliency maps\n",
    "def generate_uncertainty_map(saliency_maps):\n",
    "    return(np.std(saliency_maps,axis=0)/np.average(saliency_maps,axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrapper function to arrive at ratio output from classifiers and input\n",
    "def calculate_uncertainty(classifiers,classifier_input,output_node,visualised_layer):\n",
    "    \n",
    "    saliency_maps = generate_saliency_maps(classifiers = classifiers,\n",
    "                                  classifier_input = classifier_input,\n",
    "                                  output_node = output_node,\n",
    "                                  visualised_layer = visualised_layer)\n",
    "    \n",
    "    uncertainty_map = generate_uncertainty_map(saliency_maps)\n",
    "    \n",
    "    return(np.average(uncertainty_map))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrapper function to arrive at ratio output from classifiers and input\n",
    "def calculate_uncertainty(classifiers,classifier_input,output_node,visualised_layer):\n",
    "    \n",
    "    saliency_maps = generate_saliency_maps(classifiers = classifiers,\n",
    "                                  classifier_input = classifier_input,\n",
    "                                  output_node = output_node,\n",
    "                                  visualised_layer = visualised_layer)\n",
    "    \n",
    "    return(np.average(np.std(saliency_maps,axis=0)/np.average(saliency_maps,axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrapper function to arrive at ratio output from classifiers and input\n",
    "@jit\n",
    "def calculate_uncertainty(classifiers,classifier_input,output_node,visualised_layer):\n",
    "    \n",
    "    saliency_maps = np.zeros((len(classifiers),classifier_input.shape[0],classifier_input.shape[1]))\n",
    "    \n",
    "    for i in range(0,len(classifiers)):\n",
    "        saliency_maps[i] = visualize_saliency(model = classifiers[i],layer_idx = visualised_layer, filter_indices = output_node, seed_input = classifier_input)\n",
    "    \n",
    "    return(np.average(np.std(saliency_maps,axis=0)/np.average(saliency_maps,axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrapper function to arrive at ratio output from classifiers and input\n",
    "@jit\n",
    "def calculate_uncertainty(classifiers,classifier_input,output_node,visualised_layer):\n",
    "    \n",
    "    saliency_maps = np.zeros((len(classifiers),classifier_input.shape[0],classifier_input.shape[1]))\n",
    "    \n",
    "    for i in range(0,len(classifiers)):\n",
    "        saliency_maps[i] = visualize_saliency(model = classifiers[i],layer_idx = visualised_layer, filter_indices = output_node, seed_input = classifier_input)\n",
    "    \n",
    "    return(np.average(np.std(saliency_maps,axis=0)/np.average(saliency_maps,axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute difference of saliency maps\n",
    "@jit(nopython=True)\n",
    "def calculate_uncertainty_with_maps(saliency_maps):\n",
    "    return(np.mean(np.std(saliency_maps,axis=0)/np.average(saliency_maps,axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Generate saliency maps examples\n",
    "input_idx = 2\n",
    "maps = generate_saliency_maps(classifiers = lenets,\n",
    "                              classifier_input = testX[input_idx],\n",
    "                              output_node = np.argmax(testY[input_idx]),\n",
    "                              visualised_layer = 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise saliency maps examples\n",
    "visualize_saliency_maps(classifier_input = testX[input_idx].reshape(28,28),\n",
    "                        saliency_maps = maps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mapx in maps:\n",
    "    print(np.min(mapx), np.mean(mapx), np.max(mapx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise uncertainty map example\n",
    "uncertainty_map = generate_uncertainty_map(maps)\n",
    "plt.imshow(uncertainty_map)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.std(maps,axis=0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Compute the average difference value for each pixel (uncertainty)\n",
    "np.average(uncertainty_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Â Generating example using wrapper function\n",
    "input_idx = 4\n",
    "uncertainty = calculate_uncertainty(classifiers = lenets,\n",
    "                              classifier_input = testX[input_idx],\n",
    "                              output_node = np.argmax(testY[input_idx]),\n",
    "                              visualised_layer = 9)\n",
    "print(uncertainty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Output images that were misclassified by the singular classifier\n",
    "idx = 0\n",
    "for i in lenet.predict(testX):\n",
    "    if (np.argmax(i) != np.argmax(testY[idx])):\n",
    "        print(idx)\n",
    "    idx = idx + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uncertainties = np.zeros(testX.shape[0])\n",
    "#np.size(testX,axis=0)\n",
    "for input_idx in tqdm(range(0,np.size(testX,axis=0))):\n",
    "    uncertainties[input_idx] = calculate_uncertainty(classifiers = lenets,\n",
    "                                               classifier_input = testX[input_idx],\n",
    "                                               output_node = np.argmax(testY[input_idx]),\n",
    "                                               visualised_layer = 9)\n",
    "print(uncertainties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(0,10):\n",
    "#    visualize_saliency(model = lenet,layer_idx = 9, filter_indices = np.argmax(testY[input_idx]), seed_input = testX[input_idx])\n",
    "    classifiers = lenets\n",
    "    classifier_input = testX[input_idx]\n",
    "    output_node = np.argmax(testY[input_idx])\n",
    "    visualised_layer = 9\n",
    "    saliency_maps = np.zeros((len(classifiers),classifier_input.shape[0],classifier_input.shape[1]))\n",
    "    for i in tqdm(range(0,len(classifiers))):\n",
    "        saliency_maps[i] = visualize_saliency(model = classifiers[i],layer_idx = visualised_layer, filter_indices = output_node, seed_input = classifier_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input_idx = 8\n",
    "for i in range(0,10):\n",
    "#    visualize_saliency(model = lenet,layer_idx = 9, filter_indices = np.argmax(testY[input_idx]), seed_input = testX[input_idx])\n",
    "    classifiers = lenets\n",
    "    classifier_input = testX[input_idx]\n",
    "    output_node = np.argmax(testY[input_idx])\n",
    "    visualised_layer = 9\n",
    "    for i in tqdm(range(0,len(classifiers))):\n",
    "        visualize_saliency(model = classifiers[i],layer_idx = visualised_layer, filter_indices = output_node, seed_input = classifier_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in tqdm(range(0,5)):\n",
    "    visualize_saliency(model = lenet,layer_idx = 9, filter_indices = np.argmax(testY[input_idx]), seed_input = testX[input_idx])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uncertainties = np.zeros(testX.shape[0])\n",
    "#np.size(testX,axis=0)\n",
    "for input_idx in tqdm(range(0,np.size(testX,axis=0))):\n",
    "    maps = generate_saliency_maps(classifiers = lenets,\n",
    "                                               classifier_input = testX[input_idx],\n",
    "                                               output_node = np.argmax(testY[input_idx]),\n",
    "                                               visualised_layer = 9)\n",
    "    uncertainties[input_idx] = calculate_uncertainty(maps)\n",
    "print(uncertainties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testX.shape[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = lenets\n",
    "saliency_maps = np.zeros((testX.shape[0],\n",
    "                         len(lenets),\n",
    "                          testX.shape[1],\n",
    "                          testX.shape[2]))\n",
    "for input_idx in tqdm(range(0,np.size(saliency_maps,axis=0))):\n",
    "    classifier_input = testX[input_idx]\n",
    "    output_node = np.argmax(testY[input_idx])\n",
    "    for i in range(0,len(classifiers)):\n",
    "        saliency_maps[input_idx][i] = visualize_saliency(model = classifiers[i],\n",
    "                                                         layer_idx = 9, \n",
    "                                                         filter_indices = output_node, \n",
    "                                                         seed_input = classifier_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_maps_lambdaish(input_idx):\n",
    "    print(\"hello\")\n",
    "    classifier_input = testX[input_idx]\n",
    "    output_node = np.argmax(testY[input_idx])\n",
    "    for i in range(0,len(classifiers)):\n",
    "        saliency_maps[input_idx][i] = visualize_saliency(model = classifiers[i],\n",
    "                                                         layer_idx = visualised_layer, \n",
    "                                                         filter_indices = output_node, \n",
    "                                                         seed_input = classifier_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hello(i):\n",
    "    print(\"hello\"+str(i))\n",
    "    return(i*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Parallel(n_jobs=12,verbose=10)(delayed(hello)(i) for i in range(1000000000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "classifiers = lenets\n",
    "visualised_layer = 9\n",
    "saliency_maps = np.zeros((testX.shape[0],\n",
    "                         len(lenets),\n",
    "                          testX.shape[1],\n",
    "                          testX.shape[2]))\n",
    "saliency_maps = Parallel(n_jobs=2, verbose=10) (\n",
    "    delayed(calculate_maps_lambdaish) (input_idx)\n",
    "    for input_idx in range(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_uncertainty_lambdaish(x):\n",
    "    return(calculate_uncertainty(classifiers = lenets,\n",
    "                                 classifier_input = x,\n",
    "                                 output_node = get_ensemble_output(lenets,x),\n",
    "                                 visualised_layer = 9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in np.nditer(testX):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uncertainties = np.zeros(testX.shape[0])\n",
    "\n",
    "for x in np.nditer(testX):\n",
    "    uncertainties[i] = calculate_uncertainty(classifiers = lenets,\n",
    "                                               classifier_input = x,\n",
    "                                               output_node = get_ensemble_output(lenets,x),\n",
    "                                               visualised_layer = 9)\n",
    "    print(done)\n",
    "print(uncertainties)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "uncertainties = np.apply_along_axis(calculate_uncertainty_lambdaish,3,testX)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
